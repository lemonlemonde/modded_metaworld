{
    "algorithm": "SAC",
    "algorithm_kwargs": {
        "batch_size": 128,
        "eval_max_path_length": 500,
        "expl_max_path_length": 500,
        "min_num_steps_before_training": 3300,
        "num_epochs": 500,
        "num_eval_steps_per_epoch": 2500,
        "num_expl_steps_per_train_loop": 2500,
        "num_trains_per_train_loop": 1000
    },
    "eval_environment_kwargs": {
        "control_freq": 20,
        "controller": "OSC_POSITION",
        "env_name": "sawyer_button_press_v2",
        "hard_reset": false,
        "horizon": 500,
        "ignore_done": true,
        "reward_scale": 1.0,
        "robots": [
            "Sawyer"
        ],
        "weights": [
            -0.11253382138469098,
            0.9300155531315956,
            -0.9612006894373242,
            0.0726809882825552
        ]
    },
    "expl_environment_kwargs": {
        "control_freq": 20,
        "controller": "OSC_POSITION",
        "env_name": "sawyer_button_press_v2",
        "hard_reset": false,
        "horizon": 500,
        "ignore_done": true,
        "reward_scale": 1.0,
        "robots": [
            "Sawyer"
        ],
        "weights": [
            -0.11253382138469098,
            0.9300155531315956,
            -0.9612006894373242,
            0.0726809882825552
        ]
    },
    "policy_kwargs": {
        "hidden_sizes": [
            256,
            256
        ]
    },
    "qf_kwargs": {
        "hidden_sizes": [
            256,
            256
        ]
    },
    "replay_buffer_size": 1000000,
    "seed": 251,
    "trainer_kwargs": {
        "discount": 0.99,
        "policy_lr": 0.001,
        "qf_lr": 0.0005,
        "reward_scale": 1.0,
        "soft_target_tau": 0.005,
        "target_update_period": 5,
        "use_automatic_entropy_tuning": true
    },
    "version": "normal"
}